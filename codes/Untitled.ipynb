{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from preprocess import Preprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "    data_path = '../datas/spark.csv'\n",
    "    df = pd.read_csv(open(data_path, 'rU'))\n",
    "    df['Duplicate_null'] = df['Duplicated_issue'].apply(lambda x : pd.isnull(x))\n",
    "    prep = Preprocess()\n",
    "    df['Desc_list'] = df['Title'].apply(lambda x : prep.stem_and_stop_removal(x))\n",
    "    # Positive samples\n",
    "    df_data = df[df['Duplicate_null'] == False]\n",
    "\n",
    "\n",
    "    df_field = df_data[['Issue_id', 'Desc_list', 'Duplicated_issue', 'Resolution']]\n",
    "    df_field['dup_list'] = df_field['Duplicated_issue'].apply(lambda x: x.split(';'))\n",
    "    Dup_list = []\n",
    "    for i,r in df_field.iterrows():\n",
    "        for dup in r['dup_list']:\n",
    "            if int(r['Issue_id'].split('-')[1]) < int(dup.split('-')[1]):\n",
    "                if dup.startswith('SPARK'):\n",
    "                    Dup_list.append([r['Issue_id'], dup, r['Resolution']])\n",
    "    df_pairs_pos = pd.DataFrame(Dup_list, columns = ['Issue_id_1', 'Issue_id_2', 'Resolution'])\n",
    "\n",
    "    # Negative samples\n",
    "    neg_dup_list = []\n",
    "    cnt = 0\n",
    "    for i,r in df.iterrows():\n",
    "        if r['Duplicate_null'] == True:\n",
    "            j = 1\n",
    "            try:\n",
    "                while not df.ix[i+j]['Issue_id'].startswith('SPARK'):\n",
    "                    j += 1\n",
    "                neg_dup_list.append([r['Issue_id'], df.ix[i+j]['Issue_id'], r['Resolution']])\n",
    "                cnt += 1\n",
    "            except:\n",
    "                print traceback.print_exc() \n",
    "            \n",
    "        if cnt > len(Dup_list):\n",
    "            break\n",
    "\n",
    "    df_pairs_neg = pd.DataFrame(neg_dup_list, columns = ['Issue_id_1', 'Issue_id_2', 'Resolution'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue_id_1</th>\n",
       "      <th>Issue_id_2</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Title_1</th>\n",
       "      <th>Title_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TST-170</td>\n",
       "      <td>SPARK-290</td>\n",
       "      <td>Not A Problem</td>\n",
       "      <td>[increas, svn, limit, bin, artifact, 300mb]</td>\n",
       "      <td>[us, spark_master_ip, set, start, slav, sh]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TST-171</td>\n",
       "      <td>SPARK-290</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>[javapairrd, support, subtractbykey]</td>\n",
       "      <td>[us, spark_master_ip, set, start, slav, sh]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TST-168</td>\n",
       "      <td>SPARK-290</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[spark, shel, wil, fail, start, spark, deploy,...</td>\n",
       "      <td>[us, spark_master_ip, set, start, slav, sh]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TST-169</td>\n",
       "      <td>SPARK-290</td>\n",
       "      <td>Unresolved</td>\n",
       "      <td>[spark, stat, pack, support, common, stat, est...</td>\n",
       "      <td>[us, spark_master_ip, set, start, slav, sh]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPARK-290</td>\n",
       "      <td>SPARK-291</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[us, spark_master_ip, set, start, slav, sh]</td>\n",
       "      <td>[remov, cred, lin, build]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Issue_id_1 Issue_id_2     Resolution  \\\n",
       "0    TST-170  SPARK-290  Not A Problem   \n",
       "1    TST-171  SPARK-290        Invalid   \n",
       "2    TST-168  SPARK-290          Fixed   \n",
       "3    TST-169  SPARK-290     Unresolved   \n",
       "4  SPARK-290  SPARK-291          Fixed   \n",
       "\n",
       "                                             Title_1  \\\n",
       "0        [increas, svn, limit, bin, artifact, 300mb]   \n",
       "1               [javapairrd, support, subtractbykey]   \n",
       "2  [spark, shel, wil, fail, start, spark, deploy,...   \n",
       "3  [spark, stat, pack, support, common, stat, est...   \n",
       "4        [us, spark_master_ip, set, start, slav, sh]   \n",
       "\n",
       "                                       Title_2  label  \n",
       "0  [us, spark_master_ip, set, start, slav, sh]      0  \n",
       "1  [us, spark_master_ip, set, start, slav, sh]      0  \n",
       "2  [us, spark_master_ip, set, start, slav, sh]      0  \n",
       "3  [us, spark_master_ip, set, start, slav, sh]      0  \n",
       "4                    [remov, cred, lin, build]      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pairs_neg['Title_1'] = df_pairs_neg['Issue_id_1'].apply(lambda x: list(df[df['Issue_id'] == x]['Desc_list'])[0])\n",
    "df_pairs_neg['Title_2'] = df_pairs_neg['Issue_id_2'].apply(lambda x: list(df[df['Issue_id'] == x]['Desc_list'])[0])\n",
    "df_pairs_neg['label'] = 0\n",
    "df_pairs_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1588, 6)\n",
      "(1587, 3)\n"
     ]
    }
   ],
   "source": [
    "print df_pairs_neg.shape\n",
    "print df_pairs_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue_id_1</th>\n",
       "      <th>Issue_id_2</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Title_1</th>\n",
       "      <th>Title_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPARK-533</td>\n",
       "      <td>SPARK-736</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[kil, task, spark, request, com]</td>\n",
       "      <td>[kil, task, spark]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPARK-545</td>\n",
       "      <td>SPARK-983</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[support, extern, sort]</td>\n",
       "      <td>[support, extern, sort, rdd, sortbykey]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPARK-594</td>\n",
       "      <td>SPARK-612</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[upd, exampl, pass, jar, build, sparkcontext, ...</td>\n",
       "      <td>[upd, exampl, pass, jar, fil, sparkcontext, ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPARK-620</td>\n",
       "      <td>SPARK-671</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[default, spark_mem, high]</td>\n",
       "      <td>[spark, run, mem, fork/exec, affect, pip, python]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPARK-636</td>\n",
       "      <td>SPARK-650</td>\n",
       "      <td>Unresolved</td>\n",
       "      <td>[ad, mech, run, system, management/configurati...</td>\n",
       "      <td>[ad, setup, hook, ap, run, init, cod, execut]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Issue_id_1 Issue_id_2  Resolution  \\\n",
       "0  SPARK-533  SPARK-736       Fixed   \n",
       "1  SPARK-545  SPARK-983   Duplicate   \n",
       "2  SPARK-594  SPARK-612       Fixed   \n",
       "3  SPARK-620  SPARK-671   Duplicate   \n",
       "4  SPARK-636  SPARK-650  Unresolved   \n",
       "\n",
       "                                             Title_1  \\\n",
       "0                   [kil, task, spark, request, com]   \n",
       "1                            [support, extern, sort]   \n",
       "2  [upd, exampl, pass, jar, build, sparkcontext, ...   \n",
       "3                         [default, spark_mem, high]   \n",
       "4  [ad, mech, run, system, management/configurati...   \n",
       "\n",
       "                                             Title_2  label  \n",
       "0                                 [kil, task, spark]      1  \n",
       "1            [support, extern, sort, rdd, sortbykey]      1  \n",
       "2  [upd, exampl, pass, jar, fil, sparkcontext, ma...      1  \n",
       "3  [spark, run, mem, fork/exec, affect, pip, python]      1  \n",
       "4      [ad, setup, hook, ap, run, init, cod, execut]      1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pairs_pos['Title_1'] = df_pairs_pos['Issue_id_1'].apply(lambda x: list(df[df['Issue_id'] == x]['Desc_list'])[0])\n",
    "df_pairs_pos['Title_2'] = df_pairs_pos['Issue_id_2'].apply(lambda x: list(df[df['Issue_id'] == x]['Desc_list'])[0])\n",
    "df_pairs_pos['label'] = 1\n",
    "df_pairs_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratios = [0.6, 0.3, 0.1]\n",
    "train_set = pd.concat([df_pairs_neg.iloc[range(int(ratios[0]*len(df_pairs_neg)))],df_pairs_pos.iloc[range(int(ratios[0]*len(df_pairs_pos)))]])\n",
    "test_set = pd.concat([df_pairs_neg.iloc[range(int(ratios[0]*len(df_pairs_neg)), int((ratios[1] + ratios[0])*len(df_pairs_neg)))],df_pairs_pos.iloc[range(int(ratios[0]*len(df_pairs_pos)), int((ratios[1] + ratios[0])*len(df_pairs_pos)))]])\n",
    "vali_set = pd.concat([df_pairs_neg.iloc[range(int((ratios[1] + ratios[0])*len(df_pairs_neg)), len(df_pairs_neg))],df_pairs_pos.iloc[range(int((ratios[1] + ratios[0])*len(df_pairs_pos)), len(df_pairs_pos))]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1904, 6)\n",
      "(953, 6)\n",
      "(318, 6)\n"
     ]
    }
   ],
   "source": [
    "print train_set.shape\n",
    "print test_set.shape\n",
    "print vali_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1588, 6)\n",
      "(1587, 6)\n"
     ]
    }
   ],
   "source": [
    "print df_pairs_neg.shape\n",
    "print df_pairs_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(open('../datas/spark.csv', 'rU'))\n",
    "df['Duplicate_null'] = df['Duplicated_issue'].apply(lambda x : pd.isnull(x))\n",
    "df_data = df[df['Duplicate_null'] == False]\n",
    "prep = Preprocess()\n",
    "df_data['Desc_list'] = df_data['Title'].apply(lambda x : prep.stem_and_stop_removal(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2806, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_field = df_data[['Issue_id', 'Desc_list', 'Duplicated_issue', 'Resolution']]\n",
    "df_field.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue_id</th>\n",
       "      <th>Desc_list</th>\n",
       "      <th>Duplicated_issue</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>dup_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>SPARK-533</td>\n",
       "      <td>[kil, task, spark, -, request, com]</td>\n",
       "      <td>SPARK-736</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-736]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>SPARK-545</td>\n",
       "      <td>[support, extern, sort]</td>\n",
       "      <td>SPARK-983</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-983]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>SPARK-594</td>\n",
       "      <td>[upd, exampl, pass, jar, build, sparkcontext, ...</td>\n",
       "      <td>SPARK-612</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-612]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>SPARK-612</td>\n",
       "      <td>[upd, exampl, pass, jar, fil, sparkcontext, ma...</td>\n",
       "      <td>SPARK-594</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-594]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>SPARK-620</td>\n",
       "      <td>[default, spark_mem, high]</td>\n",
       "      <td>SPARK-671</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-671]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>SPARK-636</td>\n",
       "      <td>[ad, mech, run, system, management/configurati...</td>\n",
       "      <td>SPARK-650;SPARK-3513</td>\n",
       "      <td>Unresolved</td>\n",
       "      <td>[SPARK-650, SPARK-3513]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>SPARK-650</td>\n",
       "      <td>[ad, ``, setup, hook, '', ap, run, init, cod, ...</td>\n",
       "      <td>SPARK-636</td>\n",
       "      <td>Unresolved</td>\n",
       "      <td>[SPARK-636]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>SPARK-655</td>\n",
       "      <td>[impl, co-partitioning, aw, join, pyspark]</td>\n",
       "      <td>SPARK-5785</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-5785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>SPARK-671</td>\n",
       "      <td>[spark, run, mem, fork/exec, affect, pip, python]</td>\n",
       "      <td>SPARK-620</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-620]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>SPARK-672</td>\n",
       "      <td>[execut, get, stuck, ``, zomby, '', stat, aft,...</td>\n",
       "      <td>SPARK-1989</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-1989]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>SPARK-682</td>\n",
       "      <td>[memo, result, getpreferredloc]</td>\n",
       "      <td>SPARK-695</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-695]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>SPARK-693</td>\n",
       "      <td>[let, deploy, scripts, set, altern, conf, work...</td>\n",
       "      <td>SPARK-4616</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-4616]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>SPARK-695</td>\n",
       "      <td>[expon, recurs, getpreferredloc]</td>\n",
       "      <td>SPARK-682</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-682]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>SPARK-697</td>\n",
       "      <td>[rdd, cov]</td>\n",
       "      <td>SPARK-1296</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-1296]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>SPARK-736</td>\n",
       "      <td>[kil, task, spark]</td>\n",
       "      <td>SPARK-533</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-533]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>SPARK-750</td>\n",
       "      <td>[localsparkcontext, includ, spark, jar]</td>\n",
       "      <td>SPARK-4442</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-4442]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>SPARK-754</td>\n",
       "      <td>[multipl, spark, context, act, singl, spark, c...</td>\n",
       "      <td>SPARK-2243</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-2243]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>SPARK-761</td>\n",
       "      <td>[print, nic, er, mess, incompat, spark, bin, t...</td>\n",
       "      <td>SPARK-6828</td>\n",
       "      <td>Unresolved</td>\n",
       "      <td>[SPARK-6828]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>SPARK-786</td>\n",
       "      <td>[cle, old, work, direct, standalon, work]</td>\n",
       "      <td>SPARK-1860</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-1860]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>SPARK-791</td>\n",
       "      <td>[ad, densevect, sparsevect, mllib, replac, al,...</td>\n",
       "      <td>SPARK-1091</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-1091]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>SPARK-836</td>\n",
       "      <td>[resulttask, ser, forget, handl, gen]</td>\n",
       "      <td>SPARK-837</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-837]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>SPARK-837</td>\n",
       "      <td>[resulttask, ser, forget, handl, ``, gen, '', ...</td>\n",
       "      <td>SPARK-836</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-836]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>SPARK-868</td>\n",
       "      <td>[docu, fair, scheduler]</td>\n",
       "      <td>SPARK-892</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-892]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>SPARK-888</td>\n",
       "      <td>[kil, job, standalon, clust]</td>\n",
       "      <td>SPARK-5495</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-5495]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>SPARK-892</td>\n",
       "      <td>[ad, doc, pag, fair, scheduler]</td>\n",
       "      <td>SPARK-868</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-868]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>SPARK-926</td>\n",
       "      <td>[spark_ec2, script, ssh/scp-ing, pip, userknow...</td>\n",
       "      <td>SPARK-5403;SPARK-5403</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-5403, SPARK-5403]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>SPARK-936</td>\n",
       "      <td>[pleas, publ, jar, scal, 2, 10]</td>\n",
       "      <td>SPARK-994</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-994]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>SPARK-937</td>\n",
       "      <td>[execut, exit, cle, hav, kil, stat]</td>\n",
       "      <td>SPARK-1118</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-1118]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>SPARK-951</td>\n",
       "      <td>[gauss, mixt, model]</td>\n",
       "      <td>SPARK-3588</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-3588]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>SPARK-952</td>\n",
       "      <td>[python, vert, gauss, mixt, model]</td>\n",
       "      <td>SPARK-3588</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-3588]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>SPARK-1215</td>\n",
       "      <td>[clust, index, bound, er]</td>\n",
       "      <td>SPARK-2355</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-2355]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>SPARK-1216</td>\n",
       "      <td>[ad, onehotencod, handl, categ, feat]</td>\n",
       "      <td>SPARK-5888</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-5888]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>SPARK-1231</td>\n",
       "      <td>[dead, work, recov, autom]</td>\n",
       "      <td>SPARK-3736</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-3736]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>SPARK-1236</td>\n",
       "      <td>[upd, jetty, 9]</td>\n",
       "      <td>SPARK-1377</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-1377]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>SPARK-1256</td>\n",
       "      <td>[mast, web, ui, work, web, ui, return, 404, er]</td>\n",
       "      <td>SPARK-1265</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-1265]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>SPARK-1265</td>\n",
       "      <td>[fix, 404, found, er, ui, introduc, jetty, 9, ...</td>\n",
       "      <td>SPARK-1256</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-1256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>SPARK-1271</td>\n",
       "      <td>[streaming, annot, develop, expery, ap]</td>\n",
       "      <td>SPARK-1320</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-1320]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>SPARK-1282</td>\n",
       "      <td>[cre, spark-contrib, repo, 1, 0]</td>\n",
       "      <td>SPARK-1283</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-1283]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>SPARK-1283</td>\n",
       "      <td>[cre, spark-contrib, repo, 1, 0]</td>\n",
       "      <td>SPARK-1282</td>\n",
       "      <td>Won't Fix</td>\n",
       "      <td>[SPARK-1282]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>SPARK-1287</td>\n",
       "      <td>[yarn, alph, stabl, cli, calculateammem, routi...</td>\n",
       "      <td>SPARK-2140</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-2140]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>SPARK-1296</td>\n",
       "      <td>[mak, rdds, cov]</td>\n",
       "      <td>SPARK-697</td>\n",
       "      <td>Won't Fix</td>\n",
       "      <td>[SPARK-697]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>SPARK-1297</td>\n",
       "      <td>[upgrad, hbas, depend, 0, 98, 0]</td>\n",
       "      <td>SPARK-2720</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-2720]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>SPARK-1300</td>\n",
       "      <td>[clean-up, clar, priv, vs, publ, field, mllib]</td>\n",
       "      <td>SPARK-1357</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-1357]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>SPARK-1301</td>\n",
       "      <td>[ad, ui, el, collaps, ``, aggreg, met, execut,...</td>\n",
       "      <td>SPARK-6447</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-6447]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>SPARK-1302</td>\n",
       "      <td>[httpd, start, spark-ec2, cc2, 8xlarge]</td>\n",
       "      <td>SPARK-2649</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-2649]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>SPARK-1304</td>\n",
       "      <td>[job, fail, spot, inst, due, illegalstateexcei...</td>\n",
       "      <td>SPARK-6014</td>\n",
       "      <td>Won't Fix</td>\n",
       "      <td>[SPARK-6014]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>SPARK-1309</td>\n",
       "      <td>[sbt, assemble-deps, long, work]</td>\n",
       "      <td>SPARK-1429</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-1429]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>SPARK-1315</td>\n",
       "      <td>[spark, yarn-alpha, mvn, mast, branch, build]</td>\n",
       "      <td>SPARK-1325</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-1325]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>SPARK-1320</td>\n",
       "      <td>[cogroup, groupby, pass]</td>\n",
       "      <td>SPARK-1271</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-1271]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>SPARK-1325</td>\n",
       "      <td>[mav, build, er, spark, tool]</td>\n",
       "      <td>SPARK-1315</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-1315]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>SPARK-1337</td>\n",
       "      <td>[apply, web, ui, garb, collect, newest, stag, ...</td>\n",
       "      <td>SPARK-1411</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-1411]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>SPARK-1353</td>\n",
       "      <td>[illegalargumentexceiv, writ, disk]</td>\n",
       "      <td>SPARK-1476</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-1476]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>SPARK-1357</td>\n",
       "      <td>[streaming, ad, deploy, subsect, streaming]</td>\n",
       "      <td>SPARK-1300</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-1300]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>SPARK-1362</td>\n",
       "      <td>[web, ui, provid, pag, show, stat, stag, list,...</td>\n",
       "      <td>SPARK-4145</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-4145]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>SPARK-1363</td>\n",
       "      <td>[ad, streaming, support, spark, sql, mod]</td>\n",
       "      <td>SPARK-8360</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-8360]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>SPARK-1377</td>\n",
       "      <td>[upgrad, jetty, 8, 1, 14v20131031]</td>\n",
       "      <td>SPARK-1236</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-1236]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>SPARK-1388</td>\n",
       "      <td>[concurrentmodificationexceiv, hadoop_common, ...</td>\n",
       "      <td>SPARK-1097</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-1097]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>SPARK-1391</td>\n",
       "      <td>[blockm, transf, block, larg, 2g, siz]</td>\n",
       "      <td>SPARK-6235</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-6235]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>SPARK-1392</td>\n",
       "      <td>[loc, spark-shell, run, mem, default, set]</td>\n",
       "      <td>SPARK-1777</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-1777]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>SPARK-1405</td>\n",
       "      <td>[parallel, lat, dirichlet, alloc, lda, atop, s...</td>\n",
       "      <td>SPARK-953</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-953]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Issue_id                                          Desc_list  \\\n",
       "246    SPARK-533                [kil, task, spark, -, request, com]   \n",
       "258    SPARK-545                            [support, extern, sort]   \n",
       "307    SPARK-594  [upd, exampl, pass, jar, build, sparkcontext, ...   \n",
       "325    SPARK-612  [upd, exampl, pass, jar, fil, sparkcontext, ma...   \n",
       "333    SPARK-620                         [default, spark_mem, high]   \n",
       "349    SPARK-636  [ad, mech, run, system, management/configurati...   \n",
       "363    SPARK-650  [ad, ``, setup, hook, '', ap, run, init, cod, ...   \n",
       "368    SPARK-655         [impl, co-partitioning, aw, join, pyspark]   \n",
       "384    SPARK-671  [spark, run, mem, fork/exec, affect, pip, python]   \n",
       "385    SPARK-672  [execut, get, stuck, ``, zomby, '', stat, aft,...   \n",
       "395    SPARK-682                    [memo, result, getpreferredloc]   \n",
       "406    SPARK-693  [let, deploy, scripts, set, altern, conf, work...   \n",
       "408    SPARK-695                   [expon, recurs, getpreferredloc]   \n",
       "410    SPARK-697                                         [rdd, cov]   \n",
       "448    SPARK-736                                 [kil, task, spark]   \n",
       "462    SPARK-750            [localsparkcontext, includ, spark, jar]   \n",
       "466    SPARK-754  [multipl, spark, context, act, singl, spark, c...   \n",
       "473    SPARK-761  [print, nic, er, mess, incompat, spark, bin, t...   \n",
       "497    SPARK-786          [cle, old, work, direct, standalon, work]   \n",
       "502    SPARK-791  [ad, densevect, sparsevect, mllib, replac, al,...   \n",
       "547    SPARK-836              [resulttask, ser, forget, handl, gen]   \n",
       "548    SPARK-837  [resulttask, ser, forget, handl, ``, gen, '', ...   \n",
       "579    SPARK-868                            [docu, fair, scheduler]   \n",
       "599    SPARK-888                       [kil, job, standalon, clust]   \n",
       "603    SPARK-892                    [ad, doc, pag, fair, scheduler]   \n",
       "637    SPARK-926  [spark_ec2, script, ssh/scp-ing, pip, userknow...   \n",
       "647    SPARK-936                    [pleas, publ, jar, scal, 2, 10]   \n",
       "648    SPARK-937                [execut, exit, cle, hav, kil, stat]   \n",
       "662    SPARK-951                               [gauss, mixt, model]   \n",
       "663    SPARK-952                 [python, vert, gauss, mixt, model]   \n",
       "...          ...                                                ...   \n",
       "925   SPARK-1215                          [clust, index, bound, er]   \n",
       "926   SPARK-1216              [ad, onehotencod, handl, categ, feat]   \n",
       "941   SPARK-1231                         [dead, work, recov, autom]   \n",
       "946   SPARK-1236                                    [upd, jetty, 9]   \n",
       "966   SPARK-1256    [mast, web, ui, work, web, ui, return, 404, er]   \n",
       "975   SPARK-1265  [fix, 404, found, er, ui, introduc, jetty, 9, ...   \n",
       "981   SPARK-1271            [streaming, annot, develop, expery, ap]   \n",
       "992   SPARK-1282                   [cre, spark-contrib, repo, 1, 0]   \n",
       "993   SPARK-1283                   [cre, spark-contrib, repo, 1, 0]   \n",
       "997   SPARK-1287  [yarn, alph, stabl, cli, calculateammem, routi...   \n",
       "1006  SPARK-1296                                   [mak, rdds, cov]   \n",
       "1007  SPARK-1297                   [upgrad, hbas, depend, 0, 98, 0]   \n",
       "1010  SPARK-1300     [clean-up, clar, priv, vs, publ, field, mllib]   \n",
       "1011  SPARK-1301  [ad, ui, el, collaps, ``, aggreg, met, execut,...   \n",
       "1012  SPARK-1302            [httpd, start, spark-ec2, cc2, 8xlarge]   \n",
       "1014  SPARK-1304  [job, fail, spot, inst, due, illegalstateexcei...   \n",
       "1019  SPARK-1309                   [sbt, assemble-deps, long, work]   \n",
       "1025  SPARK-1315      [spark, yarn-alpha, mvn, mast, branch, build]   \n",
       "1030  SPARK-1320                           [cogroup, groupby, pass]   \n",
       "1035  SPARK-1325                      [mav, build, er, spark, tool]   \n",
       "1047  SPARK-1337  [apply, web, ui, garb, collect, newest, stag, ...   \n",
       "1063  SPARK-1353                [illegalargumentexceiv, writ, disk]   \n",
       "1067  SPARK-1357        [streaming, ad, deploy, subsect, streaming]   \n",
       "1072  SPARK-1362  [web, ui, provid, pag, show, stat, stag, list,...   \n",
       "1073  SPARK-1363          [ad, streaming, support, spark, sql, mod]   \n",
       "1087  SPARK-1377                 [upgrad, jetty, 8, 1, 14v20131031]   \n",
       "1098  SPARK-1388  [concurrentmodificationexceiv, hadoop_common, ...   \n",
       "1101  SPARK-1391             [blockm, transf, block, larg, 2g, siz]   \n",
       "1102  SPARK-1392         [loc, spark-shell, run, mem, default, set]   \n",
       "1115  SPARK-1405  [parallel, lat, dirichlet, alloc, lda, atop, s...   \n",
       "\n",
       "           Duplicated_issue  Resolution                  dup_list  \n",
       "246               SPARK-736       Fixed               [SPARK-736]  \n",
       "258               SPARK-983   Duplicate               [SPARK-983]  \n",
       "307               SPARK-612       Fixed               [SPARK-612]  \n",
       "325               SPARK-594   Duplicate               [SPARK-594]  \n",
       "333               SPARK-671   Duplicate               [SPARK-671]  \n",
       "349    SPARK-650;SPARK-3513  Unresolved   [SPARK-650, SPARK-3513]  \n",
       "363               SPARK-636  Unresolved               [SPARK-636]  \n",
       "368              SPARK-5785   Duplicate              [SPARK-5785]  \n",
       "384               SPARK-620       Fixed               [SPARK-620]  \n",
       "385              SPARK-1989   Duplicate              [SPARK-1989]  \n",
       "395               SPARK-695   Duplicate               [SPARK-695]  \n",
       "406              SPARK-4616   Duplicate              [SPARK-4616]  \n",
       "408               SPARK-682       Fixed               [SPARK-682]  \n",
       "410              SPARK-1296   Duplicate              [SPARK-1296]  \n",
       "448               SPARK-533       Fixed               [SPARK-533]  \n",
       "462              SPARK-4442   Duplicate              [SPARK-4442]  \n",
       "466              SPARK-2243   Duplicate              [SPARK-2243]  \n",
       "473              SPARK-6828  Unresolved              [SPARK-6828]  \n",
       "497              SPARK-1860   Duplicate              [SPARK-1860]  \n",
       "502              SPARK-1091       Fixed              [SPARK-1091]  \n",
       "547               SPARK-837   Duplicate               [SPARK-837]  \n",
       "548               SPARK-836       Fixed               [SPARK-836]  \n",
       "579               SPARK-892   Duplicate               [SPARK-892]  \n",
       "599              SPARK-5495   Duplicate              [SPARK-5495]  \n",
       "603               SPARK-868       Fixed               [SPARK-868]  \n",
       "637   SPARK-5403;SPARK-5403   Duplicate  [SPARK-5403, SPARK-5403]  \n",
       "647               SPARK-994   Duplicate               [SPARK-994]  \n",
       "648              SPARK-1118       Fixed              [SPARK-1118]  \n",
       "662              SPARK-3588   Duplicate              [SPARK-3588]  \n",
       "663              SPARK-3588   Duplicate              [SPARK-3588]  \n",
       "...                     ...         ...                       ...  \n",
       "925              SPARK-2355       Fixed              [SPARK-2355]  \n",
       "926              SPARK-5888   Duplicate              [SPARK-5888]  \n",
       "941              SPARK-3736   Duplicate              [SPARK-3736]  \n",
       "946              SPARK-1377       Fixed              [SPARK-1377]  \n",
       "966              SPARK-1265       Fixed              [SPARK-1265]  \n",
       "975              SPARK-1256       Fixed              [SPARK-1256]  \n",
       "981              SPARK-1320       Fixed              [SPARK-1320]  \n",
       "992              SPARK-1283   Duplicate              [SPARK-1283]  \n",
       "993              SPARK-1282   Won't Fix              [SPARK-1282]  \n",
       "997              SPARK-2140   Duplicate              [SPARK-2140]  \n",
       "1006              SPARK-697   Won't Fix               [SPARK-697]  \n",
       "1007             SPARK-2720       Fixed              [SPARK-2720]  \n",
       "1010             SPARK-1357       Fixed              [SPARK-1357]  \n",
       "1011             SPARK-6447       Fixed              [SPARK-6447]  \n",
       "1012             SPARK-2649       Fixed              [SPARK-2649]  \n",
       "1014             SPARK-6014   Won't Fix              [SPARK-6014]  \n",
       "1019             SPARK-1429       Fixed              [SPARK-1429]  \n",
       "1025             SPARK-1325       Fixed              [SPARK-1325]  \n",
       "1030             SPARK-1271   Duplicate              [SPARK-1271]  \n",
       "1035             SPARK-1315   Duplicate              [SPARK-1315]  \n",
       "1047             SPARK-1411       Fixed              [SPARK-1411]  \n",
       "1063             SPARK-1476   Duplicate              [SPARK-1476]  \n",
       "1067             SPARK-1300       Fixed              [SPARK-1300]  \n",
       "1072             SPARK-4145       Fixed              [SPARK-4145]  \n",
       "1073             SPARK-8360   Duplicate              [SPARK-8360]  \n",
       "1087             SPARK-1236       Fixed              [SPARK-1236]  \n",
       "1098             SPARK-1097   Duplicate              [SPARK-1097]  \n",
       "1101             SPARK-6235   Duplicate              [SPARK-6235]  \n",
       "1102             SPARK-1777   Duplicate              [SPARK-1777]  \n",
       "1115              SPARK-953       Fixed               [SPARK-953]  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_field.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue_id</th>\n",
       "      <th>Desc_list</th>\n",
       "      <th>Duplicated_issue</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>dup_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>SPARK-533</td>\n",
       "      <td>[kil, task, spark, -, request, com]</td>\n",
       "      <td>SPARK-736</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-736]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>SPARK-545</td>\n",
       "      <td>[support, extern, sort]</td>\n",
       "      <td>SPARK-983</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-983]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>SPARK-594</td>\n",
       "      <td>[upd, exampl, pass, jar, build, sparkcontext, ...</td>\n",
       "      <td>SPARK-612</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>[SPARK-612]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>SPARK-612</td>\n",
       "      <td>[upd, exampl, pass, jar, fil, sparkcontext, ma...</td>\n",
       "      <td>SPARK-594</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-594]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>SPARK-620</td>\n",
       "      <td>[default, spark_mem, high]</td>\n",
       "      <td>SPARK-671</td>\n",
       "      <td>Duplicate</td>\n",
       "      <td>[SPARK-671]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Issue_id                                          Desc_list  \\\n",
       "246  SPARK-533                [kil, task, spark, -, request, com]   \n",
       "258  SPARK-545                            [support, extern, sort]   \n",
       "307  SPARK-594  [upd, exampl, pass, jar, build, sparkcontext, ...   \n",
       "325  SPARK-612  [upd, exampl, pass, jar, fil, sparkcontext, ma...   \n",
       "333  SPARK-620                         [default, spark_mem, high]   \n",
       "\n",
       "    Duplicated_issue Resolution     dup_list  \n",
       "246        SPARK-736      Fixed  [SPARK-736]  \n",
       "258        SPARK-983  Duplicate  [SPARK-983]  \n",
       "307        SPARK-612      Fixed  [SPARK-612]  \n",
       "325        SPARK-594  Duplicate  [SPARK-594]  \n",
       "333        SPARK-671  Duplicate  [SPARK-671]  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_field['dup_list'] = df_field['Duplicated_issue'].apply(lambda x: x.split(';'))\n",
    "df_field.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1590\n"
     ]
    }
   ],
   "source": [
    "Dup_list = []\n",
    "for i,r in df_field.iterrows():\n",
    "    for dup in r['dup_list']:\n",
    "        if int(r['Issue_id'].split('-')[1]) < int(dup.split('-')[1]):\n",
    "            Dup_list.append([r['Issue_id'], dup, r['Resolution']])\n",
    "print len(Dup_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue_id_1</th>\n",
       "      <th>Issue_id_2</th>\n",
       "      <th>Resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPARK-533</td>\n",
       "      <td>SPARK-736</td>\n",
       "      <td>Fixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPARK-545</td>\n",
       "      <td>SPARK-983</td>\n",
       "      <td>Duplicate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPARK-594</td>\n",
       "      <td>SPARK-612</td>\n",
       "      <td>Fixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPARK-620</td>\n",
       "      <td>SPARK-671</td>\n",
       "      <td>Duplicate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPARK-636</td>\n",
       "      <td>SPARK-650</td>\n",
       "      <td>Unresolved</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Issue_id_1 Issue_id_2  Resolution\n",
       "0  SPARK-533  SPARK-736       Fixed\n",
       "1  SPARK-545  SPARK-983   Duplicate\n",
       "2  SPARK-594  SPARK-612       Fixed\n",
       "3  SPARK-620  SPARK-671   Duplicate\n",
       "4  SPARK-636  SPARK-650  Unresolved"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pairs = pd.DataFrame(Dup_list, columns = ['Issue_id_1', 'Issue_id_2', 'Resolution'])\n",
    "df_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Issue_id_1    SPARK-594\n",
       "Issue_id_2    SPARK-612\n",
       "Resolution        Fixed\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "df_pairs.ix[i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b5ee8e8413b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## æž„å»ºpair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# df_field[df_field['Issue_id'] == 'SPARK-533']['Desc_list']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_field\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Dup_desc_list'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_field\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Duplicated_issue'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_field\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_field\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Issue_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Desc_list'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2220\u001b[0;31m             \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:62658)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-b5ee8e8413b9>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## æž„å»ºpair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# df_field[df_field['Issue_id'] == 'SPARK-533']['Desc_list']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_field\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Dup_desc_list'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_field\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Duplicated_issue'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_field\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_field\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Issue_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Desc_list'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "## æž„å»ºpair\n",
    "# df_field[df_field['Issue_id'] == 'SPARK-533']['Desc_list']\n",
    "df_field['Dup_desc_list'] = df_field['dup_list'].apply(lambda x: list(df_field[df_field['Issue_id'] == x]['Desc_list']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
